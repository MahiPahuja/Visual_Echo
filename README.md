# Visual_Echo
This project is a real-time AI-powered vision assistant designed to aid visually impaired individuals by converting live visual input into meaningful auditory feedback. It integrates several advanced machine learning tools to interpret the environment: OpenCV for video capture, BLIP for visual question answering, CLIP for zero-shot object recognition, EasyOCR for text extraction, and pyttsx3 for offline text-to-speech output. SpeechRecognition is used to process user voice commands. The system captures frames from a webcam, analyzes them based on user queries, and provides spoken responses, enabling hands-free, context-aware interaction. It runs on modest hardware and delivers scalable, accessible visual assistance in real time.
